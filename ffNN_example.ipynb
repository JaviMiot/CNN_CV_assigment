{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYuALZOG-AMq"
   },
   "source": [
    "## Assignment: Image recognition\n",
    "- Alumno 1:\n",
    "- Alumno 2:\n",
    "- Alumno 3:\n",
    "\n",
    "The goals of the assignment are:\n",
    "* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n",
    "* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n",
    "* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n",
    "* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n",
    "\n",
    "Follow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/4oNHlRFEd71HXp4](https://drive.upm.es/s/4oNHlRFEd71HXp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:47.888598884Z",
     "start_time": "2023-10-06T13:29:47.733898014Z"
    },
    "id": "OYtqD3Oh-AMw"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "class GenericObject:\n",
    "    \"\"\"\n",
    "    Generic object data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.bb = (-1, -1, -1, -1)\n",
    "        self.category= -1\n",
    "        self.score = -1\n",
    "\n",
    "class GenericImage:\n",
    "    \"\"\"\n",
    "    Generic image data.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
    "        self.objects = list([])\n",
    "\n",
    "    def add_object(self, obj: GenericObject):\n",
    "        self.objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:47.895696607Z",
     "start_time": "2023-10-06T13:29:47.798609562Z"
    },
    "id": "I_GygShu-AMz"
   },
   "outputs": [],
   "source": [
    "categories = {0: 'Cargo plane', 1: 'Helicopter', 2: 'Small car', 3: 'Bus', 4: 'Truck', 5: 'Motorboat', 6: 'Fishing vessel', 7: 'Dump truck', 8: 'Excavator', 9: 'Building', 10: 'Storage tank', 11: 'Shipping container'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:48.047107757Z",
     "start_time": "2023-10-06T13:29:47.899181226Z"
    },
    "id": "fRBA7ReQ-AM0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_geoimage(filename):\n",
    "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    src_raster = rasterio.open(filename, 'r')\n",
    "    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n",
    "    input_type = src_raster.profile['dtype']\n",
    "    input_channels = src_raster.count\n",
    "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
    "    for band in range(input_channels):\n",
    "        img[:, :, band] = src_raster.read(band+1)\n",
    "    return img\n",
    "\n",
    "def generator_images(objs, batch_size, do_shuffle=False):\n",
    "    while True:\n",
    "        if do_shuffle:\n",
    "            np.random.shuffle(objs)\n",
    "        groups = [objs[i:i+batch_size] for i in range(0, len(objs), batch_size)]\n",
    "        for group in groups:\n",
    "            images, labels = [], []\n",
    "            for (filename, obj) in group:\n",
    "                # Load image\n",
    "                images.append(load_geoimage(filename))\n",
    "                probabilities = np.zeros(len(categories))\n",
    "                probabilities[list(categories.values()).index(obj.category)] = 1\n",
    "                labels.append(probabilities)\n",
    "            images = np.array(images).astype(np.float32)\n",
    "            labels = np.array(labels).astype(np.float32)\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:49.392405670Z",
     "start_time": "2023-10-06T13:29:49.059406441Z"
    },
    "id": "HAanJ-V0-AM1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def draw_confusion_matrix(cm, categories):\n",
    "    # Draw confusion matrix\n",
    "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diNBB3qy-AM2"
   },
   "source": [
    "#### Training\n",
    "Design and train a ffNN to deal with the “xview_recognition” classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:50.354677859Z",
     "start_time": "2023-10-06T13:29:50.239195303Z"
    },
    "id": "Orto292C-AM3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load database\n",
    "json_file = 'xview_ann_train.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:51.688578027Z",
     "start_time": "2023-10-06T13:29:51.386978797Z"
    },
    "id": "4GjFLHs4-AM4",
    "outputId": "5581df22-d4e9-42ac-9f94-061fd8c7acd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cargo plane': 635, 'Helicopter': 70, 'Small car': 4290, 'Bus': 2155, 'Truck': 2746, 'Motorboat': 1069, 'Fishing vessel': 706, 'Dump truck': 1236, 'Excavator': 789, 'Building': 4689, 'Storage tank': 1469, 'Shipping container': 1523}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = dict.fromkeys(categories.values(), 0)\n",
    "anns = []\n",
    "for json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n",
    "    image = GenericImage(json_img['filename'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    obj = GenericObject()\n",
    "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "    obj.category = json_ann['category_id']\n",
    "    # Resampling strategy to reduce training time\n",
    "    counts[obj.category] += 1\n",
    "    image.add_object(obj)\n",
    "    anns.append(image)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:52.941274537Z",
     "start_time": "2023-10-06T13:29:52.545945698Z"
    },
    "id": "NriAECvS-AM6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "anns_train, anns_valid = train_test_split(anns, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dense(len(categories)))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(len(categories)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(len(categories)))\n",
    "model_2.add(Activation('softmax'))\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(len(categories)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(len(categories)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(len(categories)))\n",
    "model_3.add(Activation('softmax'))\n",
    "\n",
    "model_list=[model_1, model_2, model_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 1: adam-lr_0.001 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 145s 266ms/step - loss: 119981.1953 - accuracy: 0.2345 - val_loss: 96986.5234 - val_accuracy: 0.2781\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 93s 174ms/step - loss: 87408.5859 - accuracy: 0.2903 - val_loss: 177651.1406 - val_accuracy: 0.0863\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 204s 382ms/step - loss: 81224.1172 - accuracy: 0.3148 - val_loss: 103538.8516 - val_accuracy: 0.3562\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 124s 233ms/step - loss: 77263.2266 - accuracy: 0.3213 - val_loss: 130655.7422 - val_accuracy: 0.1118\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 68s 127ms/step - loss: 74650.6172 - accuracy: 0.3296 - val_loss: 80166.4766 - val_accuracy: 0.3943\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 71s 128ms/step - loss: 73599.5469 - accuracy: 0.3362 - val_loss: 89980.8828 - val_accuracy: 0.2507\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 66s 120ms/step - loss: 71908.1641 - accuracy: 0.3406 - val_loss: 87271.1094 - val_accuracy: 0.4051\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 75s 141ms/step - loss: 69929.9922 - accuracy: 0.3390 - val_loss: 288877.5000 - val_accuracy: 0.0737\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 93s 174ms/step - loss: 71156.0938 - accuracy: 0.3427 - val_loss: 72454.9297 - val_accuracy: 0.3686\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 155s 290ms/step - loss: 67992.9219 - accuracy: 0.3488 - val_loss: 77474.3672 - val_accuracy: 0.2753\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 194s 364ms/step - loss: 69081.4609 - accuracy: 0.3517 - val_loss: 81409.9453 - val_accuracy: 0.2914\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 211s 394ms/step - loss: 68785.5938 - accuracy: 0.3528 - val_loss: 78593.0781 - val_accuracy: 0.2086\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 104s 196ms/step - loss: 69654.4531 - accuracy: 0.3521 - val_loss: 63429.5312 - val_accuracy: 0.2130\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 199s 372ms/step - loss: 66073.8984 - accuracy: 0.3613 - val_loss: 62762.9414 - val_accuracy: 0.2715\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 127s 238ms/step - loss: 67617.5312 - accuracy: 0.3581 - val_loss: 64037.2461 - val_accuracy: 0.3683\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 67034.8203 - accuracy: 0.3568 - val_loss: 87784.6875 - val_accuracy: 0.3730\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 66649.0703 - accuracy: 0.3652 - val_loss: 70583.2500 - val_accuracy: 0.4046\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 59s 111ms/step - loss: 66614.2500 - accuracy: 0.3611 - val_loss: 67782.7500 - val_accuracy: 0.2855\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 67659.8047 - accuracy: 0.3597 - val_loss: 68284.6875 - val_accuracy: 0.3536\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 59s 111ms/step - loss: 64268.7461 - accuracy: 0.3683 - val_loss: 126404.4453 - val_accuracy: 0.1120\n",
      "Best validation model: epoch 7  - val_accuracy 0.40505144000053406\n",
      "Modelo 2: adam-lr_0.001 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 70s 129ms/step - loss: 21.0069 - accuracy: 0.2140 - val_loss: 2.4584 - val_accuracy: 0.2325\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 70s 130ms/step - loss: 2.4480 - accuracy: 0.2138 - val_loss: 2.4346 - val_accuracy: 0.2325\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 70s 131ms/step - loss: 2.4253 - accuracy: 0.2131 - val_loss: 2.4125 - val_accuracy: 0.2325\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 68s 128ms/step - loss: 2.4052 - accuracy: 0.2196 - val_loss: 2.3924 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 68s 128ms/step - loss: 2.3867 - accuracy: 0.2164 - val_loss: 2.3742 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 68s 127ms/step - loss: 2.3704 - accuracy: 0.2140 - val_loss: 2.3578 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 67s 126ms/step - loss: 2.3542 - accuracy: 0.2174 - val_loss: 2.3428 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 61s 114ms/step - loss: 2.3416 - accuracy: 0.2184 - val_loss: 2.3294 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 2.3307 - accuracy: 0.2133 - val_loss: 2.3175 - val_accuracy: 0.2327\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 2.3175 - accuracy: 0.2183 - val_loss: 2.3065 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 61s 114ms/step - loss: 2.3106 - accuracy: 0.2120 - val_loss: 2.2968 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 419s 785ms/step - loss: 2.2980 - accuracy: 0.2205 - val_loss: 2.2878 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 75s 141ms/step - loss: 2.2937 - accuracy: 0.2134 - val_loss: 2.2800 - val_accuracy: 0.2327\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 80s 150ms/step - loss: 2.2822 - accuracy: 0.2159 - val_loss: 2.2727 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 89s 167ms/step - loss: 2.2809 - accuracy: 0.2131 - val_loss: 2.2664 - val_accuracy: 0.2327\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 86s 162ms/step - loss: 2.2732 - accuracy: 0.2167 - val_loss: 2.2606 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 88s 166ms/step - loss: 2.2623 - accuracy: 0.2205 - val_loss: 2.2551 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 86s 162ms/step - loss: 2.2658 - accuracy: 0.2140 - val_loss: 2.2505 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 80s 150ms/step - loss: 2.2608 - accuracy: 0.2156 - val_loss: 2.2463 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 97s 182ms/step - loss: 2.2519 - accuracy: 0.2172 - val_loss: 2.2423 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 4  - val_accuracy 0.2326941043138504\n",
      "Modelo 3: adam-lr_0.001 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 114s 212ms/step - loss: 4.8919 - accuracy: 0.2150 - val_loss: 2.4587 - val_accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 87s 163ms/step - loss: 2.4475 - accuracy: 0.2163 - val_loss: 2.4345 - val_accuracy: 0.2327\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 71s 133ms/step - loss: 2.4251 - accuracy: 0.2162 - val_loss: 2.4124 - val_accuracy: 0.2327\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 70s 130ms/step - loss: 2.4052 - accuracy: 0.2151 - val_loss: 2.3924 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 2.3865 - accuracy: 0.2195 - val_loss: 2.3742 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 71s 133ms/step - loss: 2.3694 - accuracy: 0.2147 - val_loss: 2.3577 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 70s 131ms/step - loss: 2.3574 - accuracy: 0.2152 - val_loss: 2.3432 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.3387 - accuracy: 0.2164 - val_loss: 2.3295 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 62s 117ms/step - loss: 2.3302 - accuracy: 0.2144 - val_loss: 2.3175 - val_accuracy: 0.2327\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.3182 - accuracy: 0.2166 - val_loss: 2.3066 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 2.3069 - accuracy: 0.2194 - val_loss: 2.2966 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 62s 117ms/step - loss: 2.3030 - accuracy: 0.2113 - val_loss: 2.2880 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 65s 122ms/step - loss: 2.2910 - accuracy: 0.2169 - val_loss: 2.2800 - val_accuracy: 0.2327\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2883 - accuracy: 0.2151 - val_loss: 2.2731 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 65s 121ms/step - loss: 2.2734 - accuracy: 0.2185 - val_loss: 2.2664 - val_accuracy: 0.2327\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.2742 - accuracy: 0.2137 - val_loss: 2.2606 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.2678 - accuracy: 0.2153 - val_loss: 2.2554 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2615 - accuracy: 0.2199 - val_loss: 2.2506 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.2593 - accuracy: 0.2128 - val_loss: 2.2464 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2520 - accuracy: 0.2175 - val_loss: 2.2424 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 1  - val_accuracy 0.2326941043138504\n",
      "Modelo 4: adam-lr_0.01 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 75s 139ms/step - loss: 1102901.6250 - accuracy: 0.2471 - val_loss: 730278.0000 - val_accuracy: 0.2558\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 71s 132ms/step - loss: 859292.9375 - accuracy: 0.2954 - val_loss: 569262.9375 - val_accuracy: 0.4039\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 73s 136ms/step - loss: 770882.8750 - accuracy: 0.3157 - val_loss: 659305.2500 - val_accuracy: 0.3019\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 72s 135ms/step - loss: 747691.3125 - accuracy: 0.3251 - val_loss: 994831.3750 - val_accuracy: 0.3796\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 68s 127ms/step - loss: 732462.6875 - accuracy: 0.3371 - val_loss: 793923.0625 - val_accuracy: 0.4062\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 71s 132ms/step - loss: 729956.3125 - accuracy: 0.3337 - val_loss: 943575.6875 - val_accuracy: 0.2025\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 68s 127ms/step - loss: 709296.5625 - accuracy: 0.3472 - val_loss: 913260.4375 - val_accuracy: 0.1899\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 62s 116ms/step - loss: 686830.5000 - accuracy: 0.3439 - val_loss: 627805.4375 - val_accuracy: 0.3653\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 698284.6875 - accuracy: 0.3523 - val_loss: 1051131.0000 - val_accuracy: 0.2280\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 59s 111ms/step - loss: 674405.1250 - accuracy: 0.3479 - val_loss: 662646.7500 - val_accuracy: 0.3440\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 64s 119ms/step - loss: 699238.3125 - accuracy: 0.3497 - val_loss: 900185.3125 - val_accuracy: 0.4273\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 669918.4375 - accuracy: 0.3597 - val_loss: 515035.9062 - val_accuracy: 0.3155\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 660106.9375 - accuracy: 0.3589 - val_loss: 543610.3750 - val_accuracy: 0.3901\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 659885.3125 - accuracy: 0.3570 - val_loss: 586090.1250 - val_accuracy: 0.4074\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 660987.8750 - accuracy: 0.3666 - val_loss: 704151.7500 - val_accuracy: 0.3202\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 69s 129ms/step - loss: 666200.5000 - accuracy: 0.3662 - val_loss: 331087.4062 - val_accuracy: 0.3714\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 69s 130ms/step - loss: 661276.0000 - accuracy: 0.3611 - val_loss: 324133.5938 - val_accuracy: 0.4401\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 71s 133ms/step - loss: 649939.2500 - accuracy: 0.3673 - val_loss: 696787.8750 - val_accuracy: 0.3031\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 69s 130ms/step - loss: 645736.8125 - accuracy: 0.3686 - val_loss: 935395.5625 - val_accuracy: 0.4343\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 71s 132ms/step - loss: 612767.0625 - accuracy: 0.3695 - val_loss: 1298906.0000 - val_accuracy: 0.1305\n",
      "Best validation model: epoch 17  - val_accuracy 0.44013094902038574\n",
      "Modelo 5: adam-lr_0.01 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 74s 137ms/step - loss: 2.2403 - accuracy: 0.2156 - val_loss: 2.2180 - val_accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 64s 119ms/step - loss: 2.2248 - accuracy: 0.2160 - val_loss: 2.2072 - val_accuracy: 0.2327\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 64s 119ms/step - loss: 2.2158 - accuracy: 0.2162 - val_loss: 2.2011 - val_accuracy: 0.2327\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2126 - accuracy: 0.2158 - val_loss: 2.1976 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 62s 115ms/step - loss: 2.2092 - accuracy: 0.2161 - val_loss: 2.1950 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 62s 117ms/step - loss: 2.2068 - accuracy: 0.2163 - val_loss: 2.1933 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 62s 115ms/step - loss: 2.2064 - accuracy: 0.2155 - val_loss: 2.1919 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 56s 106ms/step - loss: 2.2054 - accuracy: 0.2153 - val_loss: 2.1909 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 56s 105ms/step - loss: 2.2026 - accuracy: 0.2171 - val_loss: 2.1899 - val_accuracy: 0.2327\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 57s 106ms/step - loss: 2.2044 - accuracy: 0.2153 - val_loss: 2.1892 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 57s 106ms/step - loss: 2.2023 - accuracy: 0.2161 - val_loss: 2.1886 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 57s 107ms/step - loss: 2.2005 - accuracy: 0.2161 - val_loss: 2.1881 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 57s 106ms/step - loss: 2.2021 - accuracy: 0.2160 - val_loss: 2.1877 - val_accuracy: 0.2327\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 55s 102ms/step - loss: 2.2027 - accuracy: 0.2154 - val_loss: 2.1873 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 56s 104ms/step - loss: 2.2023 - accuracy: 0.2155 - val_loss: 2.1872 - val_accuracy: 0.2327\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 56s 105ms/step - loss: 2.1987 - accuracy: 0.2167 - val_loss: 2.1867 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 2.2003 - accuracy: 0.2158 - val_loss: 2.1863 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 56s 104ms/step - loss: 2.2001 - accuracy: 0.2165 - val_loss: 2.1861 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 2.1994 - accuracy: 0.2161 - val_loss: 2.1858 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 2.2006 - accuracy: 0.2153 - val_loss: 2.1857 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 1  - val_accuracy 0.2326941043138504\n",
      "Modelo 6: adam-lr_0.01 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 66s 123ms/step - loss: 2.2396 - accuracy: 0.2157 - val_loss: 2.2181 - val_accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.2235 - accuracy: 0.2150 - val_loss: 2.2072 - val_accuracy: 0.2327\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.2202 - accuracy: 0.2143 - val_loss: 2.2016 - val_accuracy: 0.2327\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2113 - accuracy: 0.2167 - val_loss: 2.1977 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2101 - accuracy: 0.2172 - val_loss: 2.1952 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.2061 - accuracy: 0.2176 - val_loss: 2.1933 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.2044 - accuracy: 0.2157 - val_loss: 2.1920 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 57s 107ms/step - loss: 2.2025 - accuracy: 0.2151 - val_loss: 2.1911 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 57s 106ms/step - loss: 2.2053 - accuracy: 0.2162 - val_loss: 2.1900 - val_accuracy: 0.2327\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 56s 106ms/step - loss: 2.2043 - accuracy: 0.2190 - val_loss: 2.1891 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 55s 103ms/step - loss: 2.2052 - accuracy: 0.2122 - val_loss: 2.1888 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 5174s 10s/step - loss: 2.2014 - accuracy: 0.2152 - val_loss: 2.1885 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 62s 116ms/step - loss: 2.1997 - accuracy: 0.2166 - val_loss: 2.1878 - val_accuracy: 0.2327\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 62s 115ms/step - loss: 2.2014 - accuracy: 0.2127 - val_loss: 2.1879 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 62s 115ms/step - loss: 2.2025 - accuracy: 0.2208 - val_loss: 2.1870 - val_accuracy: 0.2327\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 61s 115ms/step - loss: 2.2018 - accuracy: 0.2141 - val_loss: 2.1868 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 64s 119ms/step - loss: 2.1968 - accuracy: 0.2161 - val_loss: 2.1867 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 61s 114ms/step - loss: 2.2007 - accuracy: 0.2147 - val_loss: 2.1865 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 2.2014 - accuracy: 0.2168 - val_loss: 2.1861 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2028 - accuracy: 0.2161 - val_loss: 2.1859 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 1  - val_accuracy 0.2326941043138504\n",
      "Modelo 7: adam-lr_0.1 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 74s 138ms/step - loss: 10990384.0000 - accuracy: 0.2520 - val_loss: 7643610.5000 - val_accuracy: 0.2484\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 73s 137ms/step - loss: 8636614.0000 - accuracy: 0.2924 - val_loss: 20423580.0000 - val_accuracy: 0.1878\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 7402361.0000 - accuracy: 0.3210 - val_loss: 8241377.0000 - val_accuracy: 0.3012\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 7497917.5000 - accuracy: 0.3290 - val_loss: 7895110.5000 - val_accuracy: 0.3950\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 69s 130ms/step - loss: 7582674.0000 - accuracy: 0.3290 - val_loss: 4643333.0000 - val_accuracy: 0.4383\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 70s 131ms/step - loss: 7204464.0000 - accuracy: 0.3368 - val_loss: 5026723.0000 - val_accuracy: 0.3412\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 70s 131ms/step - loss: 7391526.5000 - accuracy: 0.3333 - val_loss: 11543188.0000 - val_accuracy: 0.2334\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 64s 119ms/step - loss: 7166033.0000 - accuracy: 0.3416 - val_loss: 4332339.0000 - val_accuracy: 0.3113\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 62s 117ms/step - loss: 6791265.0000 - accuracy: 0.3502 - val_loss: 6810198.5000 - val_accuracy: 0.2383\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 6761987.5000 - accuracy: 0.3504 - val_loss: 8888212.0000 - val_accuracy: 0.4217\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 61s 113ms/step - loss: 7046447.0000 - accuracy: 0.3515 - val_loss: 13103781.0000 - val_accuracy: 0.3159\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 6700963.5000 - accuracy: 0.3634 - val_loss: 4840154.0000 - val_accuracy: 0.4020\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 6603546.0000 - accuracy: 0.3667 - val_loss: 6026581.0000 - val_accuracy: 0.3351\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 6738417.0000 - accuracy: 0.3551 - val_loss: 8251125.5000 - val_accuracy: 0.2729\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 59s 110ms/step - loss: 6660745.5000 - accuracy: 0.3657 - val_loss: 5842227.5000 - val_accuracy: 0.3417\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 60s 112ms/step - loss: 6404590.0000 - accuracy: 0.3659 - val_loss: 4949816.0000 - val_accuracy: 0.2919\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 6834224.5000 - accuracy: 0.3571 - val_loss: 7920830.0000 - val_accuracy: 0.3754\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 6349008.5000 - accuracy: 0.3694 - val_loss: 6363901.5000 - val_accuracy: 0.2884\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 6475859.5000 - accuracy: 0.3696 - val_loss: 6283484.5000 - val_accuracy: 0.3155\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 61s 114ms/step - loss: 6337674.0000 - accuracy: 0.3720 - val_loss: 11693873.0000 - val_accuracy: 0.2881\n",
      "Best validation model: epoch 5  - val_accuracy 0.4382600486278534\n",
      "Modelo 8: adam-lr_0.1 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 2.2034 - accuracy: 0.2148 - val_loss: 2.1851 - val_accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 71s 132ms/step - loss: 2.1968 - accuracy: 0.2170 - val_loss: 2.1835 - val_accuracy: 0.2327\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 71s 133ms/step - loss: 2.1970 - accuracy: 0.2147 - val_loss: 2.1838 - val_accuracy: 0.2327\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 67s 126ms/step - loss: 2.2031 - accuracy: 0.2128 - val_loss: 2.1837 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 67s 125ms/step - loss: 2.1965 - accuracy: 0.2176 - val_loss: 2.1835 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 65s 122ms/step - loss: 2.1973 - accuracy: 0.2116 - val_loss: 2.1836 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 66s 124ms/step - loss: 2.1960 - accuracy: 0.2163 - val_loss: 2.1829 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 1765s 3s/step - loss: 2.1998 - accuracy: 0.2169 - val_loss: 2.1839 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 61s 114ms/step - loss: 2.1993 - accuracy: 0.2107 - val_loss: 2.1830 - val_accuracy: 0.2327\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 61s 115ms/step - loss: 2.1994 - accuracy: 0.2150 - val_loss: 2.1816 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 61s 115ms/step - loss: 2.1963 - accuracy: 0.2161 - val_loss: 2.1827 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 60s 113ms/step - loss: 2.1984 - accuracy: 0.2098 - val_loss: 2.1817 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 74s 139ms/step - loss: 2.1973 - accuracy: 0.2179 - val_loss: 2.1847 - val_accuracy: 0.1981\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 65s 122ms/step - loss: 2.1987 - accuracy: 0.2124 - val_loss: 2.1832 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.1984 - accuracy: 0.2177 - val_loss: 2.1817 - val_accuracy: 0.2327\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 72s 136ms/step - loss: 2.1936 - accuracy: 0.2133 - val_loss: 2.1821 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 71s 133ms/step - loss: 2.2040 - accuracy: 0.2130 - val_loss: 2.1842 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.2001 - accuracy: 0.2149 - val_loss: 2.1820 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 63s 118ms/step - loss: 2.2005 - accuracy: 0.2149 - val_loss: 2.1821 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 66s 124ms/step - loss: 2.1900 - accuracy: 0.2192 - val_loss: 2.1822 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 1  - val_accuracy 0.2326941043138504\n",
      "Modelo 9: adam-lr_0.1 - batch_size: 32 epochs: 20\n",
      "Epoch 1/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 2.2010 - accuracy: 0.2129 - val_loss: 2.1861 - val_accuracy: 0.2327\n",
      "Epoch 2/20\n",
      "535/535 [==============================] - 72s 135ms/step - loss: 2.1998 - accuracy: 0.2133 - val_loss: 2.1842 - val_accuracy: 0.2327\n",
      "Epoch 3/20\n",
      "535/535 [==============================] - 72s 134ms/step - loss: 2.1985 - accuracy: 0.2140 - val_loss: 2.1832 - val_accuracy: 0.2327\n",
      "Epoch 4/20\n",
      "535/535 [==============================] - 74s 139ms/step - loss: 2.1981 - accuracy: 0.2148 - val_loss: 2.1841 - val_accuracy: 0.2327\n",
      "Epoch 5/20\n",
      "535/535 [==============================] - 77s 144ms/step - loss: 2.1984 - accuracy: 0.2155 - val_loss: 2.1833 - val_accuracy: 0.2327\n",
      "Epoch 6/20\n",
      "535/535 [==============================] - 74s 139ms/step - loss: 2.1986 - accuracy: 0.2157 - val_loss: 2.1829 - val_accuracy: 0.2327\n",
      "Epoch 7/20\n",
      "535/535 [==============================] - 75s 140ms/step - loss: 2.1985 - accuracy: 0.2162 - val_loss: 2.1830 - val_accuracy: 0.2327\n",
      "Epoch 8/20\n",
      "535/535 [==============================] - 68s 127ms/step - loss: 2.1981 - accuracy: 0.2148 - val_loss: 2.1826 - val_accuracy: 0.2327\n",
      "Epoch 9/20\n",
      "535/535 [==============================] - 66s 124ms/step - loss: 2.1995 - accuracy: 0.2148 - val_loss: 2.1839 - val_accuracy: 0.1978\n",
      "Epoch 10/20\n",
      "535/535 [==============================] - 69s 129ms/step - loss: 2.1973 - accuracy: 0.2157 - val_loss: 2.1817 - val_accuracy: 0.2327\n",
      "Epoch 11/20\n",
      "535/535 [==============================] - 63s 117ms/step - loss: 2.1982 - accuracy: 0.2131 - val_loss: 2.1840 - val_accuracy: 0.2327\n",
      "Epoch 12/20\n",
      "535/535 [==============================] - 66s 123ms/step - loss: 2.1986 - accuracy: 0.2148 - val_loss: 2.1828 - val_accuracy: 0.2327\n",
      "Epoch 13/20\n",
      "535/535 [==============================] - 62s 117ms/step - loss: 2.1995 - accuracy: 0.2122 - val_loss: 2.1834 - val_accuracy: 0.2327\n",
      "Epoch 14/20\n",
      "535/535 [==============================] - 59s 110ms/step - loss: 2.1975 - accuracy: 0.2132 - val_loss: 2.1826 - val_accuracy: 0.2327\n",
      "Epoch 15/20\n",
      "535/535 [==============================] - 69s 129ms/step - loss: 2.1983 - accuracy: 0.2110 - val_loss: 2.1843 - val_accuracy: 0.1978\n",
      "Epoch 16/20\n",
      "535/535 [==============================] - 65s 121ms/step - loss: 2.1984 - accuracy: 0.2146 - val_loss: 2.1832 - val_accuracy: 0.2327\n",
      "Epoch 17/20\n",
      "535/535 [==============================] - 62s 115ms/step - loss: 2.1997 - accuracy: 0.2151 - val_loss: 2.1825 - val_accuracy: 0.2327\n",
      "Epoch 18/20\n",
      "535/535 [==============================] - 64s 120ms/step - loss: 2.1968 - accuracy: 0.2134 - val_loss: 2.1831 - val_accuracy: 0.2327\n",
      "Epoch 19/20\n",
      "535/535 [==============================] - 59s 110ms/step - loss: 2.1991 - accuracy: 0.2152 - val_loss: 2.1832 - val_accuracy: 0.2327\n",
      "Epoch 20/20\n",
      "535/535 [==============================] - 57s 107ms/step - loss: 2.1990 - accuracy: 0.2156 - val_loss: 2.1829 - val_accuracy: 0.2327\n",
      "Best validation model: epoch 1  - val_accuracy 0.2326941043138504\n",
      "Mejor tasa de aprendizaje: 0.01\n",
      "Mejor optimizador: <keras.src.optimizers.legacy.gradient_descent.SGD object at 0x7f7934c92650>\n",
      "Precisión en el conjunto de validación: 0.44013094902038574\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Definir valores para tasas de aprendizaje\n",
    "learning_rates = [1e-3, 1e-2, 1e-1]\n",
    "\n",
    "# Definir optimizadores con tasas de aprendizaje específicas\n",
    "optimizers = {f'adam-lr_{lr}':Adam(learning_rate=lr) for lr in learning_rates} | {f'SGD-lr_{lr}':SGD(learning_rate=lr) for lr in learning_rates}\n",
    "\n",
    "# Almacenar los resultados de la validación\n",
    "resultados = []\n",
    "\n",
    "# Generate the list of objects from annotations\n",
    "objs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\n",
    "objs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n",
    "# Generators\n",
    "batch_size = 32\n",
    "train_generator = generator_images(objs_train, batch_size, do_shuffle=True)\n",
    "valid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)\n",
    "\n",
    "train_steps = math.ceil(len(objs_train)/batch_size)\n",
    "valid_steps = math.ceil(len(objs_valid)/batch_size)\n",
    "epochs = 20\n",
    "# Iterar sobre todas las combinaciones de optimizadores y tasas de aprendizaje\n",
    "model_id = 1\n",
    "for key, optimizer in optimizers.items():\n",
    "        for model in model_list:\n",
    "            model_name = 'Modelo ' + str(model_id) + ': ' + key + ' - ' + f'batch_size: {batch_size} epochs: {epochs}'\n",
    "            \n",
    "            print(model_name)\n",
    "\n",
    "            model.compile(optimizer=optimizer,\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir= 'logs_ffnn/'+model_name+'{}'.format(time()))\n",
    "\n",
    "            # Entrenar el modelo con los datos de entrenamiento y validación\n",
    "            h = model.fit(train_generator, steps_per_epoch=train_steps, epochs=epochs, batch_size=1024, validation_data=valid_generator, validation_steps=valid_steps, verbose=1, callbacks=[tensorboard])\n",
    "            \n",
    "            # Best validation model\n",
    "            best_idx = int(np.argmax(h.history['val_accuracy']))\n",
    "            best_value = np.max(h.history['val_accuracy'])\n",
    "            print('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))\n",
    "\n",
    "            resultados.append({'model': str(model_id), 'learning_rate': optimizer.lr.numpy(), 'optimizer': optimizer, 'best epoch idx':best_idx+1, 'val_accuracy': best_value})\n",
    "            model_id += 1\n",
    "\n",
    "# Encontrar la mejor combinación de hiperparámetros basada en la precisión\n",
    "mejor_configuracion = max(resultados, key=lambda x: x['val_accuracy'])\n",
    "\n",
    "print(\"Mejor tasa de aprendizaje:\", mejor_configuracion['learning_rate'])\n",
    "print(\"Mejor optimizador:\", mejor_configuracion['optimizer'])\n",
    "print(\"Precisión en el conjunto de validación:\", mejor_configuracion['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:56.123227463Z",
     "start_time": "2023-10-06T13:29:53.523949443Z"
    },
    "id": "BNkjbY2e-AM7",
    "outputId": "47bde031-306f-464e-8e22-cc70a7fb7c67"
   },
   "outputs": [],
   "source": [
    "# Load architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "print('Load model')\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "\n",
    "model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Hidden layers\n",
    "\n",
    "model.add(Dense(len(categories)))\n",
    "\n",
    "# Output layer\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:29:56.124072624Z",
     "start_time": "2023-10-06T13:29:56.098552032Z"
    },
    "id": "-aSlKtG6-AM7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Learning rate is changed to 0.001\n",
    "# opt = Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8, amsgrad=True, clipnorm=1.0, clipvalue=0.5)\n",
    "opt = SGD(learning_rate=1e-3, momentum=0.9, clipnorm=1.0, clipvalue=0.5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:30:00.423165893Z",
     "start_time": "2023-10-06T13:30:00.403263469Z"
    },
    "id": "GGAJEfpB-AM8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from time import time\n",
    "\n",
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint('model.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.1, patience=10, verbose=1)\n",
    "# early_stop = EarlyStopping('val_accuracy', patience=40, verbose=1)\n",
    "terminate = TerminateOnNaN()\n",
    "tensorboard = TensorBoard(log_dir= 'logs_ffnn/{}'.format(time()))\n",
    "callbacks = [tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:30:01.960819288Z",
     "start_time": "2023-10-06T13:30:01.906083581Z"
    },
    "id": "Yht-QqUH-AM8"
   },
   "outputs": [],
   "source": [
    "# Generate the list of objects from annotations\n",
    "objs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\n",
    "objs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]\n",
    "# Generators\n",
    "batch_size = 32\n",
    "train_generator = generator_images(objs_train, batch_size, do_shuffle=True)\n",
    "valid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:58:26.219192607Z",
     "start_time": "2023-10-06T13:30:03.359181716Z"
    },
    "id": "TrfpdECs-AM9",
    "outputId": "21d89b78-d94c-442e-9bc2-517654c0b614"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "print('Training model')\n",
    "epochs = 50\n",
    "train_steps = math.ceil(len(objs_train)/batch_size)\n",
    "valid_steps = math.ceil(len(objs_valid)/batch_size)\n",
    "h = model.fit(train_generator, steps_per_epoch=train_steps, validation_data=valid_generator, validation_steps=valid_steps, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "# Best validation model\n",
    "best_idx = int(np.argmax(h.history['val_accuracy']))\n",
    "best_value = np.max(h.history['val_accuracy'])\n",
    "print('Best validation model: epoch ' + str(best_idx+1), ' - val_accuracy ' + str(best_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IMMO_mT-AM9"
   },
   "source": [
    "#### Testing\n",
    "Try to improve the results provided in the Moodle competition wiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:06:30.286976834Z",
     "start_time": "2023-10-06T14:06:30.243469253Z"
    },
    "id": "Sgh9KqIW-AM-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load database\n",
    "json_file = 'xview_ann_test.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:06:31.133707360Z",
     "start_time": "2023-10-06T14:06:31.083694789Z"
    },
    "id": "tJr_-xCt-AM-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "anns = []\n",
    "for json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n",
    "    image = GenericImage(json_img['filename'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    obj = GenericObject()\n",
    "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "    obj.category = json_ann['category_id']\n",
    "    image.add_object(obj)\n",
    "    anns.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:08:35.738057751Z",
     "start_time": "2023-10-06T14:06:31.815602308Z"
    },
    "id": "TGs2zqfv-AM_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# model.load_weights('model.hdf5', by_name=True)\n",
    "y_true, y_pred = [], []\n",
    "for ann in anns:\n",
    "    # Load image\n",
    "    image = load_geoimage(ann.filename)\n",
    "    for obj_pred in ann.objects:\n",
    "        # Generate prediction\n",
    "        warped_image = np.expand_dims(image, 0)\n",
    "        predictions = model.predict(warped_image)\n",
    "        # Save prediction\n",
    "        pred_category = list(categories.values())[np.argmax(predictions)]\n",
    "        pred_score = np.max(predictions)\n",
    "        y_true.append(obj_pred.category)\n",
    "        y_pred.append(pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:08:36.681807803Z",
     "start_time": "2023-10-06T14:08:35.715011537Z"
    },
    "id": "YqYKVsEp-AM_",
    "outputId": "d256367d-744e-487d-f44c-cd106dad3484"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\n",
    "draw_confusion_matrix(cm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:08:36.690503230Z",
     "start_time": "2023-10-06T14:08:36.685130731Z"
    },
    "id": "jD1zLfCd-ANA",
    "outputId": "3a3154f8-c349-4a58-a129-d7aa04a588cb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the accuracy\n",
    "correct_samples_class = np.diag(cm).astype(float)\n",
    "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
    "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
    "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
    "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
    "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
    "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
    "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
    "for idx in range(len(categories)):\n",
    "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
    "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
    "    tp = cm[idx, idx]\n",
    "    fp = sum(cm[:, idx]) - tp\n",
    "    fn = sum(cm[idx, :]) - tp\n",
    "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
    "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
    "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
    "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
    "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
    "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
    "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
    "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
    "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
    "    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOPI5zc8-ANB"
   },
   "source": [
    "#### Report\n",
    "\n",
    "You must prepare a report (PDF) describing:\n",
    "* The problems and data sets (briefly).\n",
    "* The process that you have followed to reach your solution for the “xview_recognition” benchmark, including your intermediate results. You must discuss and compare these results properly.\n",
    "* Final network architectures, including optimization algorithms, regularization methods (dropout, data augmentation, etc.), number of layers/parameters, and performance obtained with your model on the train/valid/test data sets, including the plots of the evolution of losses and accuracy.\n",
    "* It would also be very valuable your feedback on the use of “Cesvima” or “Google Colab\" services.\n",
    "\n",
    "In the submission via Moodle, attach your Python (.py) or Jupyter Notebook (.ipynb) source file, including in the report all results of computations attached to the code that generated them.\n",
    "\n",
    "The assignment must be done in groups of 3 students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 22:26:00.100405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-21 22:26:00.100479: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-21 22:26:00.100528: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 22:26:00.108533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 22:26:03.152555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 22:26:03.159369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 22:26:03.159834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "TensorBoard 2.14.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_base = os.path.abspath(os.getcwd())\n",
    "path = f\"{path_base}/logs_ffnn/\"\n",
    "subdirs = [f'{f.path.replace(path,\"\").replace(\" \",\"_\").replace(\":\",\"__\")}:\"{f.path}\"' for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "total_path = \",\".join(subdirs)\n",
    "\n",
    "\n",
    "# for index, log_directory in enumerate(subdirs):\n",
    "#     cmd = f'tensorboard --logdir {log_directory} --host localhost --port {6006+index}'\n",
    "#     os.system(cmd)\n",
    "\n",
    "os.system(f'tensorboard --logdir_spec {total_path} --host localhost --port 6006')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNdH4hNj-ANB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
